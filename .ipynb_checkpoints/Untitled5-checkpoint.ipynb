{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa6ca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/19 14:32:03 WARN Utils: Your hostname, gautam resolves to a loopback address: 127.0.1.1; using 192.168.149.227 instead (on interface wlp3s0)\n",
      "22/01/19 14:32:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/gautam/.local/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/19 14:32:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/19 14:32:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/01/19 14:32:04 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/01/19 14:32:04 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/01/19 14:32:04 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/01/19 14:32:04 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pratise\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4954c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_spark = spark.read.csv('test.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f79f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+------------+\n",
      "|    name|age|experience|salary|  department|\n",
      "+--------+---+----------+------+------------+\n",
      "|  mukesh| 23|        10|  8999|data science|\n",
      "|  rakesh| 34|         3|   877|         IOT|\n",
      "|  rukesh| 33|         2|  2333|    Big Data|\n",
      "|    ravi| 23|        33| 23000|    Big Data|\n",
      "|    sonu| 34|         4|  3422|data science|\n",
      "|    monu| 34|         2|  3673|data science|\n",
      "|rajkumar| 43|         4|  6765|         IOT|\n",
      "|   Subhu| 33|         7|  5555|    Big Data|\n",
      "|  gautam| 44|         4| 87878|          AI|\n",
      "|  suresh| 88|        46| 87878|         NLP|\n",
      "|   sunny| 77|        77|  7677|         IVP|\n",
      "+--------+---+----------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d21823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience', 'salary', 'department']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d538f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['age', 'experience'], outputCol='Independent Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a2ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(py_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a801369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+------------+--------------------+\n",
      "|    name|age|experience|salary|  department|Independent Features|\n",
      "+--------+---+----------+------+------------+--------------------+\n",
      "|  mukesh| 23|        10|  8999|data science|         [23.0,10.0]|\n",
      "|  rakesh| 34|         3|   877|         IOT|          [34.0,3.0]|\n",
      "|  rukesh| 33|         2|  2333|    Big Data|          [33.0,2.0]|\n",
      "|    ravi| 23|        33| 23000|    Big Data|         [23.0,33.0]|\n",
      "|    sonu| 34|         4|  3422|data science|          [34.0,4.0]|\n",
      "|    monu| 34|         2|  3673|data science|          [34.0,2.0]|\n",
      "|rajkumar| 43|         4|  6765|         IOT|          [43.0,4.0]|\n",
      "|   Subhu| 33|         7|  5555|    Big Data|          [33.0,7.0]|\n",
      "|  gautam| 44|         4| 87878|          AI|          [44.0,4.0]|\n",
      "|  suresh| 88|        46| 87878|         NLP|         [88.0,46.0]|\n",
      "|   sunny| 77|        77|  7677|         IVP|         [77.0,77.0]|\n",
      "+--------+---+----------+------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b396da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience', 'salary', 'department', 'Independent Features']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf18e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data = output.select(\"Independent Features\", \"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0e9937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|salary|\n",
      "+--------------------+------+\n",
      "|         [23.0,10.0]|  8999|\n",
      "|          [34.0,3.0]|   877|\n",
      "|          [33.0,2.0]|  2333|\n",
      "|         [23.0,33.0]| 23000|\n",
      "|          [34.0,4.0]|  3422|\n",
      "|          [34.0,2.0]|  3673|\n",
      "|          [43.0,4.0]|  6765|\n",
      "|          [33.0,7.0]|  5555|\n",
      "|          [44.0,4.0]| 87878|\n",
      "|         [88.0,46.0]| 87878|\n",
      "|         [77.0,77.0]|  7677|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adaccb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/19 14:44:59 WARN Instrumentation: [fe0e2321] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/01/19 14:45:00 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/01/19 14:45:00 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/01/19 14:45:00 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
    "regressor = LinearRegression(featuresCol=\"Independent Features\", labelCol=\"salary\")\n",
    "regressor =  regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043aedc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1060.8708, -235.4202])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1561d8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25286.48696912715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9502afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d859245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|Independent Features|salary|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|         [23.0,10.0]|  8999|-3240.660235086354|\n",
      "|          [43.0,4.0]|  6765|19389.276809830608|\n",
      "|          [44.0,4.0]| 87878|20450.147611172073|\n",
      "+--------------------+------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautam/.local/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_result.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c29d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30763.929811248297"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.meanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e85d77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1618565641.8037164"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f776f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
